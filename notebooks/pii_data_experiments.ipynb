{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PII Detection Experiments with Hugging Face Dataset\n",
    "\n",
    "This notebook explores the [ai4privacy/pii-masking-200k](https://huggingface.co/datasets/ai4privacy/pii-masking-200k) dataset and tests OpenAI's ability to detect PII."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T14:43:09.902971Z",
     "start_time": "2026-01-12T14:43:09.898904Z"
    }
   },
   "source": [
    "# Install required packages if needed\n",
    "# !pip install datasets openai python-dotenv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T14:43:14.765831Z",
     "start_time": "2026-01-12T14:43:12.130159Z"
    }
   },
   "source": "import os\nimport random\nfrom pathlib import Path\nfrom datasets import load_dataset\nfrom openai import OpenAI\nimport json\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file in parent directory (project root)\nenv_file = Path(__file__).parent.parent / '.env' if '__file__' in globals() else Path.cwd().parent / '.env'\n\nprint(f\"Looking for .env file at: {env_file}\")\nif env_file.exists():\n    print(f\"âœ“ Found .env file\")\n    load_dotenv(dotenv_path=env_file)\nelse:\n    print(f\"âš ï¸  .env file not found at {env_file}\")\n    print(\"   Will try loading from default locations\")\n    load_dotenv()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for .env file at: /Users/kodlan/workspaces/python/pii-llm/.env\n",
      "âœ“ Found .env file\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Loading the PII masking dataset from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T14:43:18.371643Z",
     "start_time": "2026-01-12T14:43:16.125120Z"
    }
   },
   "source": "print(\"Loading dataset...\")\n\n# Get Hugging Face token from environment for faster downloads (optional)\nhf_token = os.getenv(\"HF_TOKEN\")\n\nif hf_token:\n    # Check if it's a placeholder value\n    if hf_token.startswith(\"your-\") or \"placeholder\" in hf_token.lower() or \"example\" in hf_token.lower():\n        print(\"âš ï¸  HF_TOKEN appears to be a placeholder value - will use unauthenticated access\")\n        print(\"   Edit your .env file and add your actual Hugging Face token for faster downloads\")\n        hf_token = None\n    else:\n        print(\"âœ“ Using HF_TOKEN for authenticated access (faster downloads)\")\nelse:\n    print(\"âš ï¸  No HF_TOKEN found - using unauthenticated access (slower)\")\n    print(\"   Get a token at https://huggingface.co/settings/tokens to speed up downloads\")\n\n# Load dataset with token if available\ndataset = load_dataset(\"ai4privacy/pii-masking-200k\", token=hf_token if hf_token else None)\ntrain_data = dataset[\"train\"]\n\nprint(f\"\\nDataset loaded successfully!\")\nprint(f\"Total number of samples: {len(train_data)}\")\nprint(f\"\\nColumn names: {train_data.column_names}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "âœ“ Using HF_TOKEN for authenticated access (faster downloads)\n",
      "\n",
      "Dataset loaded successfully!\n",
      "Total number of samples: 209261\n",
      "\n",
      "Column names: ['source_text', 'target_text', 'privacy_mask', 'span_labels', 'mbert_text_tokens', 'mbert_bio_labels', 'id', 'language', 'set']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Sample Random Entries\n\nFiltering the dataset to English samples only, then selecting 5 random samples with a fixed seed for reproducibility."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T14:43:20.055137Z",
     "start_time": "2026-01-12T14:43:20.039754Z"
    }
   },
   "source": "# Set random seed for reproducibility\nrandom.seed(42)\n\n# Filter dataset to English only\nprint(\"Filtering dataset to English samples only...\")\nenglish_data = train_data.filter(lambda x: x['language'] == 'en')\nprint(f\"English samples: {len(english_data)} out of {len(train_data)} total\")\n\n# Sample 5 random indices from English data\nsample_indices = random.sample(range(len(english_data)), 5)\nprint(f\"\\nSelected indices from English dataset: {sample_indices}\")\n\n# Get the samples\nsamples = [english_data[i] for i in sample_indices]\nprint(f\"Successfully sampled {len(samples)} English entries\")\n\n# Verify all samples are English\nlanguages = [s['language'] for s in samples]\nprint(f\"Languages: {languages}\")\nassert all(lang == 'en' for lang in languages), \"Not all samples are English!\"",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering dataset to English samples only...\n",
      "English samples: 43501 out of 209261 total\n",
      "\n",
      "Selected indices from English dataset: [41905, 7296, 1639, 18024, 16049]\n",
      "Successfully sampled 5 English entries\n",
      "Languages: ['en', 'en', 'en', 'en', 'en']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Samples\n",
    "\n",
    "Let's look at each sample to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T14:43:21.257225Z",
     "start_time": "2026-01-12T14:43:21.251765Z"
    }
   },
   "source": [
    "for i, sample in enumerate(samples, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SAMPLE {i} (ID: {sample['id']}, Language: {sample['language']})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“„ SOURCE TEXT (with PII):\")\n",
    "    print(f\"{sample['source_text']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”’ TARGET TEXT (masked):\")\n",
    "    print(f\"{sample['target_text']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ·ï¸  GROUND TRUTH PII:\")\n",
    "    for pii_item in sample['privacy_mask']:\n",
    "        print(f\"  - {pii_item['label']:20s} : '{pii_item['value']}' (pos {pii_item['start']}-{pii_item['end']})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE 1 (ID: 207666, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "Analyst, we need you to investigate further about the Mozilla/5.0 (Windows NT 5.1; WOW64; rv:12.2) Gecko/20100101 Firefox/12.2.4 case. Draw insights from this situation and propose how it can affect our company policies.\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "[JOBTYPE], we need you to investigate further about the [USERAGENT] case. Draw insights from this situation and propose how it can affect our company policies.\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - JOBTYPE              : 'Analyst' (pos 0-7)\n",
      "  - USERAGENT            : 'Mozilla/5.0 (Windows NT 5.1; WOW64; rv:12.2) Gecko/20100101 Firefox/12.2.4' (pos 54-128)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 2 (ID: 173057, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "Our main blockchain consultant identified 13eBdNVhaUZ6RPaCbiD1jPWVnEKaRCUU and 0xffff97e7cbbdc819da9d6ae8ef80deaf4bf39cec as two significant cryptocurrency addresses to monitor considering their possible impact on our business continuity.\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "Our main blockchain consultant identified [BITCOINADDRESS] and [ETHEREUMADDRESS] as two significant cryptocurrency addresses to monitor considering their possible impact on our business continuity.\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - BITCOINADDRESS       : '13eBdNVhaUZ6RPaCbiD1jPWVnEKaRCUU' (pos 42-74)\n",
      "  - ETHEREUMADDRESS      : '0xffff97e7cbbdc819da9d6ae8ef80deaf4bf39cec' (pos 79-121)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 3 (ID: 167400, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "We've recently shipped new pharmaceutical goods to Quebec through Northeast route. Make sure the goods are monitored in-transit via GPS Coordinate: [-42.306,172.4064]. Notify the Admin Specialist in case of delays.\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "We've recently shipped new pharmaceutical goods to [STATE] through [ORDINALDIRECTION] route. Make sure the goods are monitored in-transit via GPS Coordinate: [NEARBYGPSCOORDINATE]. Notify the Admin [JOBTYPE] in case of delays.\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - STATE                : 'Quebec' (pos 51-57)\n",
      "  - ORDINALDIRECTION     : 'Northeast' (pos 66-75)\n",
      "  - NEARBYGPSCOORDINATE  : '[-42.306,172.4064]' (pos 148-166)\n",
      "  - JOBTYPE              : 'Specialist' (pos 185-195)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 4 (ID: 183785, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "Hello Adella, your request to our mental health service was flagged due to the 29-977557-300592-0. Kindly provide a different device for safety.\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "Hello [FIRSTNAME], your request to our mental health service was flagged due to the [PHONEIMEI]. Kindly provide a different device for safety.\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - FIRSTNAME            : 'Adella' (pos 6-12)\n",
      "  - PHONEIMEI            : '29-977557-300592-0' (pos 79-97)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 5 (ID: 181810, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "Our global education initiative seems to have stirred interest in the Southwest region. Our webpage Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_5_8 rv:6.0; MS) AppleWebKit/538.2.1 (KHTML, like Gecko) Version/7.1.6 Safari/538.2.1 hit a stunning 9017629466736622.\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "Our global education initiative seems to have stirred interest in the [ORDINALDIRECTION] region. Our webpage [USERAGENT] hit a stunning [MASKEDNUMBER].\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - ORDINALDIRECTION     : 'Southwest' (pos 70-79)\n",
      "  - USERAGENT            : 'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_5_8 rv:6.0; MS) AppleWebKit/538.2.1 (KHTML, like Gecko) Version/7.1.6 Safari/538.2.1' (pos 100-229)\n",
      "  - MASKEDNUMBER         : '9017629466736622' (pos 245-261)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup OpenAI API\n",
    "\n",
    "Configure the OpenAI client using the API key from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T14:43:23.526764Z",
     "start_time": "2026-01-12T14:43:23.476088Z"
    }
   },
   "source": [
    "# Get API key from environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Validate API key\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables.\\n\\n\")\n",
    "\n",
    "# Check if it's still the placeholder value from .env.example\n",
    "if api_key.startswith(\"your-\") or \"placeholder\" in api_key.lower() or \"example\" in api_key.lower():\n",
    "    raise ValueError(\"OPENAI_API_KEY appears to be the placeholder value from .env.example.\\n\\n\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "print(\"âœ“ OpenAI client initialized successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ OpenAI client initialized successfully\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PII Detection Prompt\n",
    "\n",
    "Create a prompt that asks the LLM to identify all PII in the text."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T14:46:23.330620Z",
     "start_time": "2026-01-12T14:46:23.326491Z"
    }
   },
   "source": [
    "def create_pii_detection_prompt(text):\n",
    "    \"\"\"Create a prompt for PII detection.\"\"\"\n",
    "    return f\"\"\"Identify all personally identifiable information (PII) in the following text.\n",
    "               For each piece of PII found, provide:\n",
    "               1. The exact text/value\n",
    "               2. The type of PII (e.g., FIRSTNAME, EMAIL, PHONENUMBER, ADDRESS, SSN, etc.)\n",
    "               3. The character position (start and end)\n",
    "\n",
    "               Return your response as a JSON array where each item has: \"value\", \"label\", \"start\", \"end\"\n",
    "\n",
    "               Text to analyze: {text}\n",
    "               Only return the JSON, no additional text.\"\"\"\n",
    "\n",
    "# Test the prompt with the first sample\n",
    "test_prompt = create_pii_detection_prompt(samples[0]['source_text'])\n",
    "print(\"Example prompt:\")\n",
    "print(test_prompt[:500] + \"...\" if len(test_prompt) > 500 else test_prompt)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example prompt:\n",
      "Identify all personally identifiable information (PII) in the following text.\n",
      "               For each piece of PII found, provide:\n",
      "               1. The exact text/value\n",
      "               2. The type of PII (e.g., FIRSTNAME, EMAIL, PHONENUMBER, ADDRESS, SSN, etc.)\n",
      "               3. The character position (start and end)\n",
      "\n",
      "               Return your response as a JSON array where each item has: \"value\", \"label\", \"start\", \"end\"\n",
      "\n",
      "               Text to analyze: Analyst, we need you to investigate furth...\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Send Samples to OpenAI for PII Detection\n",
    "\n",
    "Process each sample and get PII detection results from OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def detect_pii_with_model(sample, model_name, client):\n",
    "    \"\"\"\n",
    "    Detect PII in a sample using a specific OpenAI model.\n",
    "    \n",
    "    Args:\n",
    "        sample: Dataset sample containing 'source_text'\n",
    "        model_name: OpenAI model name (e.g., 'gpt-4o-mini', 'gpt-5.2')\n",
    "        client: OpenAI client instance\n",
    "        \n",
    "    Returns:\n",
    "        dict: Result containing detected PII or error information\n",
    "    \"\"\"\n",
    "    # Create the prompt\n",
    "    prompt = create_pii_detection_prompt(sample['source_text'])\n",
    "    \n",
    "    # Call OpenAI API\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a PII detection expert. Return only valid JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0,  # deterministic output\n",
    "            response_format={\"type\": \"json_object\"}  # ensure JSON response\n",
    "        )\n",
    "        \n",
    "        # Extract the response\n",
    "        llm_response = response.choices[0].message.content\n",
    "        \n",
    "        # Try to parse as JSON\n",
    "        try:\n",
    "            detected_pii = json.loads(llm_response)\n",
    "        except json.JSONDecodeError:\n",
    "            detected_pii = {\"error\": \"Invalid JSON response\"}\n",
    "        \n",
    "        # Return result\n",
    "        return {\n",
    "            \"sample_id\": sample['id'],\n",
    "            \"source_text\": sample['source_text'],\n",
    "            \"ground_truth\": sample['privacy_mask'],\n",
    "            \"model\": model_name,\n",
    "            \"detected_pii\": detected_pii,\n",
    "            \"raw_response\": llm_response\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"sample_id\": sample['id'],\n",
    "            \"source_text\": sample['source_text'],\n",
    "            \"ground_truth\": sample['privacy_mask'],\n",
    "            \"model\": model_name,\n",
    "            \"error\": str(e)\n",
    "        }"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T14:46:29.265794Z",
     "start_time": "2026-01-12T14:46:29.260014Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Send Samples to OpenAI for PII Detection\n\nProcess each sample and get PII detection results from two OpenAI models:\n- **gpt-4o-mini**: Cost-effective baseline model\n- **gpt-5.2**: Latest and most capable model (as of Jan 2026)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T14:46:44.526249Z",
     "start_time": "2026-01-12T14:46:32.338160Z"
    }
   },
   "source": [
    "# Models to test\n",
    "models_to_test = [\n",
    "    \"gpt-4o-mini\",  # Cost-effective baseline\n",
    "    \"gpt-5.2\"       # Latest flagship model\n",
    "]\n",
    "\n",
    "results = {model: [] for model in models_to_test}\n",
    "\n",
    "for i, sample in enumerate(samples, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing Sample {i}/{len(samples)} (ID: {sample['id']})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Test with each model\n",
    "    for model_name in models_to_test:\n",
    "        print(f\"\\nðŸ¤– Testing with {model_name}...\")\n",
    "        \n",
    "        result = detect_pii_with_model(sample, model_name, client)\n",
    "        results[model_name].append(result)\n",
    "        \n",
    "        # Show the response\n",
    "        if 'error' in result:\n",
    "            print(f\"   âŒ Error: {result['error']}\")\n",
    "        else:\n",
    "            print(f\"   âœ“ Response: {result['raw_response'][:200]}...\" if len(result['raw_response']) > 200 else f\"   âœ“ Response: {result['raw_response']}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing Sample 1/5 (ID: 207666)\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: {}\n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: {}\n",
      "\n",
      "================================================================================\n",
      "Processing Sample 2/5 (ID: 173057)\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: {\n",
      "  \"PII\": []\n",
      "}\n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: {\n",
      "  \"value\": \"13eBdNVhaUZ6RPaCbiD1jPWVnEKaRCUU\",\n",
      "  \"label\": \"CRYPTO_ADDRESS\",\n",
      "  \"start\": 50,\n",
      "  \"end\": 84\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "Processing Sample 3/5 (ID: 167400)\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: {\n",
      "  \"PII\": []\n",
      "}\n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: {\"error\":\"No PII found in the provided text.\",\"pii\":[]}\n",
      "\n",
      "================================================================================\n",
      "Processing Sample 4/5 (ID: 183785)\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: {\n",
      "  \"PII\": [\n",
      "    {\n",
      "      \"value\": \"Adella\",\n",
      "      \"label\": \"FIRSTNAME\",\n",
      "      \"start\": 6,\n",
      "      \"end\": 12\n",
      "    },\n",
      "    {\n",
      "      \"value\": \"29-977557-300592-0\",\n",
      "      \"label\": \"SSN\",\n",
      "      \"start\": 56,\n",
      "   ...\n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: {\n",
      "  \"value\": \"Adella\",\n",
      "  \"label\": \"FIRSTNAME\",\n",
      "  \"start\": 6,\n",
      "  \"end\": 12\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "Processing Sample 5/5 (ID: 181810)\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: {\n",
      "  \"PII\": []\n",
      "}\n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: {\n",
      "  \"value\": \"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_5_8 rv:6.0; MS) AppleWebKit/538.2.1 (KHTML, like Gecko) Version/7.1.6 Safari/538.2.1\",\n",
      "  \"label\": \"USER_AGENT\",\n",
      "  \"start\": 90,\n",
      "  \"end\": 230\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
