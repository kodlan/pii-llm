{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PII Detection Experiments with Hugging Face Dataset\n",
    "\n",
    "This notebook explores the [ai4privacy/pii-masking-200k](https://huggingface.co/datasets/ai4privacy/pii-masking-200k) dataset and tests OpenAI's ability to detect PII."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T19:24:50.261579Z",
     "start_time": "2026-01-12T19:24:50.258821Z"
    }
   },
   "source": [
    "# Install required packages if needed\n",
    "# !pip install datasets openai python-dotenv"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T16:36:36.568193Z",
     "start_time": "2026-01-13T16:36:32.189392Z"
    }
   },
   "source": "import os\nimport random\nfrom pathlib import Path\nfrom datasets import load_dataset\nfrom openai import OpenAI\nimport json\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file in parent directory (project root)\nenv_file = Path(__file__).parent.parent / '.env' if '__file__' in globals() else Path.cwd().parent / '.env'\n\nprint(f\"Looking for .env file at: {env_file}\")\nif env_file.exists():\n    print(f\"âœ“ Found .env file\")\n    load_dotenv(dotenv_path=env_file)\nelse:\n    print(f\"âš ï¸  .env file not found at {env_file}\")\n    print(\"   Will try loading from default locations\")\n    load_dotenv()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for .env file at: /Users/kodlan/workspaces/python/pii-llm/.env\n",
      "âœ“ Found .env file\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Loading the PII masking dataset from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T16:36:41.601347Z",
     "start_time": "2026-01-13T16:36:38.791962Z"
    }
   },
   "source": "print(\"Loading dataset...\")\n\n# Get Hugging Face token from environment for faster downloads (optional)\nhf_token = os.getenv(\"HF_TOKEN\")\n\nif hf_token:\n    # Check if it's a placeholder value\n    if hf_token.startswith(\"your-\") or \"placeholder\" in hf_token.lower() or \"example\" in hf_token.lower():\n        print(\"âš ï¸  HF_TOKEN appears to be a placeholder value - will use unauthenticated access\")\n        print(\"   Edit your .env file and add your actual Hugging Face token for faster downloads\")\n        hf_token = None\n    else:\n        print(\"âœ“ Using HF_TOKEN for authenticated access (faster downloads)\")\nelse:\n    print(\"âš ï¸  No HF_TOKEN found - using unauthenticated access (slower)\")\n    print(\"   Get a token at https://huggingface.co/settings/tokens to speed up downloads\")\n\n# Load dataset with token if available\ndataset = load_dataset(\"ai4privacy/pii-masking-200k\", token=hf_token if hf_token else None)\ntrain_data = dataset[\"train\"]\n\nprint(f\"\\nDataset loaded successfully!\")\nprint(f\"Total number of samples: {len(train_data)}\")\nprint(f\"\\nColumn names: {train_data.column_names}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "âœ“ Using HF_TOKEN for authenticated access (faster downloads)\n",
      "\n",
      "Dataset loaded successfully!\n",
      "Total number of samples: 209261\n",
      "\n",
      "Column names: ['source_text', 'target_text', 'privacy_mask', 'span_labels', 'mbert_text_tokens', 'mbert_bio_labels', 'id', 'language', 'set']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Sample Random Entries\n\nFiltering the dataset to English samples only, then selecting 5 random samples with a fixed seed for reproducibility."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:51:51.976112Z",
     "start_time": "2026-01-13T18:51:51.513184Z"
    }
   },
   "source": [
    "# Set number of samples\n",
    "number_samples = 20\n",
    "number_prompt_samples = 1000\n",
    "\n",
    "# Filter dataset to English only\n",
    "print(\"Filtering dataset to English samples only...\")\n",
    "english_data = train_data.filter(lambda x: x['language'] == 'en')\n",
    "print(f\"English samples: {len(english_data)} out of {len(train_data)} total\")\n",
    "\n",
    "\n",
    "def get_samples_from_index(data, start_index, num_samples):\n",
    "    \"\"\"\n",
    "    Get samples from the dataset starting at a specific index.\n",
    "    \n",
    "    Args:\n",
    "        data: The dataset to sample from\n",
    "        start_index: Starting index in the dataset\n",
    "        num_samples: Number of samples to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        list: List of samples\n",
    "    \"\"\"\n",
    "    samples = [data[i] for i in range(start_index, start_index + num_samples)]\n",
    "    \n",
    "    # Verify all samples are English\n",
    "    languages = [s['language'] for s in samples]\n",
    "    assert all(lang == 'en' for lang in languages), \"Not all samples are English!\"\n",
    "    \n",
    "    return samples\n",
    "\n",
    "\n",
    "# Get prompt_samples from the beginning of the dataset\n",
    "prompt_samples = get_samples_from_index(english_data, start_index=0, num_samples=number_prompt_samples)\n",
    "print(f\"\\nSuccessfully sampled {len(prompt_samples)} English entries for prompt_samples (indices 0-{number_prompt_samples-1})\")\n",
    "\n",
    "# Get the main samples from later in the dataset\n",
    "samples_start_index = 10000\n",
    "samples = get_samples_from_index(english_data, start_index=samples_start_index, num_samples=number_samples)\n",
    "print(f\"Successfully sampled {len(samples)} English entries for samples (indices {samples_start_index}-{samples_start_index + number_samples - 1})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering dataset to English samples only...\n",
      "English samples: 43501 out of 209261 total\n",
      "\n",
      "Successfully sampled 1000 English entries for prompt_samples (indices 0-999)\n",
      "Successfully sampled 20 English entries for samples (indices 10000-10019)\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Samples\n",
    "\n",
    "Let's look at each sample to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:52:59.894889Z",
     "start_time": "2026-01-13T18:52:59.888873Z"
    }
   },
   "source": [
    "for i in range(5):\n",
    "    sample = samples[i]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SAMPLE {i} (ID: {sample['id']}, Language: {sample['language']})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“„ SOURCE TEXT (with PII):\")\n",
    "    print(f\"{sample['source_text']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”’ TARGET TEXT (masked):\")\n",
    "    print(f\"{sample['target_text']}\")\n",
    "    \n",
    "    print(f\"\\nðŸ·ï¸  GROUND TRUTH PII:\")\n",
    "    for pii_item in sample['privacy_mask']:\n",
    "        print(f\"  - {pii_item['label']:20s} : '{pii_item['value']}' (pos {pii_item['start']}-{pii_item['end']})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE 0 (ID: 175761, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "To settle the charges of Pakistan Rupee746,208.95 for your 9 Non-binary child's counseling sessions, kindly use the attached american_express 5943919109159496.\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "To settle the charges of [CURRENCY][AMOUNT] for your [AGE] [GENDER] child's counseling sessions, kindly use the attached [CREDITCARDISSUER] [CREDITCARDNUMBER].\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - CURRENCY             : 'Pakistan Rupee' (pos 25-39)\n",
      "  - AMOUNT               : '746,208.95' (pos 39-49)\n",
      "  - AGE                  : '9' (pos 59-60)\n",
      "  - GENDER               : 'Non-binary' (pos 61-71)\n",
      "  - CREDITCARDISSUER     : 'american_express' (pos 125-141)\n",
      "  - CREDITCARDNUMBER     : '5943919109159496' (pos 142-158)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 1 (ID: 175762, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "Bobby_Wisozk has noted violations of Port Muriel's zoning laws for commercial property on Toy Landing. A cease and desist order expected.\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "[USERNAME] has noted violations of [CITY]'s zoning laws for commercial property on [STREET]. A cease and desist order expected.\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - USERNAME             : 'Bobby_Wisozk' (pos 0-12)\n",
      "  - CITY                 : 'Port Muriel' (pos 37-48)\n",
      "  - STREET               : 'Toy Landing' (pos 90-101)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 2 (ID: 175763, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "Your finance team has been tasked with creating a detailed report on all our assets and liabilities. Please send me the report on my secondary email at Apt. 508. Use the password yIh8ROIfIkPl for any encrypted files.\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "Your finance team has been tasked with creating a detailed report on all our assets and liabilities. Please send me the report on my secondary email at [SECONDARYADDRESS]. Use the password [PASSWORD] for any encrypted files.\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - SECONDARYADDRESS     : 'Apt. 508' (pos 152-160)\n",
      "  - PASSWORD             : 'yIh8ROIfIkPl' (pos 179-191)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 3 (ID: 175764, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "The Arts Education plan for this semester includes a talk from 1kLwc9VckFtgAJQ1aM3WneZAuyBu from [-71.3107,55.0959]\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "The Arts Education plan for this semester includes a talk from [BITCOINADDRESS] from [NEARBYGPSCOORDINATE]\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - BITCOINADDRESS       : '1kLwc9VckFtgAJQ1aM3WneZAuyBu' (pos 63-91)\n",
      "  - NEARBYGPSCOORDINATE  : '[-71.3107,55.0959]' (pos 97-115)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 4 (ID: 175765, Language: en)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ SOURCE TEXT (with PII):\n",
      "In light of recent developments, please advise about updating our patent strategy. You can reach out to our office at Apt. 926, Washington County. Regards, The Assistant.\n",
      "\n",
      "ðŸ”’ TARGET TEXT (masked):\n",
      "In light of recent developments, please advise about updating our patent strategy. You can reach out to our office at [SECONDARYADDRESS], [COUNTY]. Regards, The [JOBTYPE].\n",
      "\n",
      "ðŸ·ï¸  GROUND TRUTH PII:\n",
      "  - SECONDARYADDRESS     : 'Apt. 926' (pos 118-126)\n",
      "  - COUNTY               : 'Washington County' (pos 128-145)\n",
      "  - JOBTYPE              : 'Assistant' (pos 160-169)\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup OpenAI API\n",
    "\n",
    "Configure the OpenAI client using the API key from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:53:14.332531Z",
     "start_time": "2026-01-13T18:53:14.271316Z"
    }
   },
   "source": [
    "# Get API key from environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Validate API key\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables.\\n\\n\")\n",
    "\n",
    "# Check if it's still the placeholder value from .env.example\n",
    "if api_key.startswith(\"your-\") or \"placeholder\" in api_key.lower() or \"example\" in api_key.lower():\n",
    "    raise ValueError(\"OPENAI_API_KEY appears to be the placeholder value from .env.example.\\n\\n\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "print(\"âœ“ OpenAI client initialized successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ OpenAI client initialized successfully\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Send Samples to OpenAI for PII Detection\n",
    "\n",
    "Process each sample and get PII detection results from OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "def detect_pii_with_model(sample, model_name, client, get_prompt: Callable[[str], str]):\n",
    "    \"\"\"\n",
    "    Detect PII in a sample using a specific OpenAI model.\n",
    "    \n",
    "    Args:\n",
    "        sample: Dataset sample containing 'source_text'\n",
    "        model_name: OpenAI model name (e.g., 'gpt-4o-mini', 'gpt-5.2')\n",
    "        client: OpenAI client instance\n",
    "        get_prompt: function that generates prompt\n",
    "    Returns:\n",
    "        dict: Result containing detected PII or error information\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = get_prompt(sample['source_text'])\n",
    "\n",
    "    result = {\n",
    "            \"sample_id\": sample['id'],\n",
    "            \"source_text\": sample['source_text'],\n",
    "            \"ground_truth\": sample['privacy_mask'],\n",
    "            \"model\": model_name\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a PII detection expert. Return only valid JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0,  # deterministic output\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        # Extract the response\n",
    "        llm_response = response.choices[0].message.content\n",
    "        \n",
    "        detected_pii = json.loads(llm_response)\n",
    "\n",
    "        result[\"detected_pii\"] = detected_pii\n",
    "        result[\"raw_response\"] = llm_response\n",
    "\n",
    "        return result\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        result[\"error\"] = \"Invalid JSON response\"\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        result[\"error\"] = str(e)\n",
    "        return result\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:53:15.043734Z",
     "start_time": "2026-01-13T18:53:15.038128Z"
    }
   },
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Send Samples to OpenAI for PII Detection\n\nProcess each sample and get PII detection results from two OpenAI models:\n- **gpt-4o-mini**: Cost-effective baseline model\n- **gpt-5.2**: Latest and most capable model (as of Jan 2026)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:53:16.650237Z",
     "start_time": "2026-01-13T18:53:16.642222Z"
    }
   },
   "source": [
    "models_to_test = [\n",
    "    \"gpt-4o-mini\",  # Cost-effective baseline\n",
    "    \"gpt-5.2\"       # Latest flagship model\n",
    "]\n",
    "\n",
    "def print_result(result):\n",
    "    if 'error' in result:\n",
    "        print(f\"   âŒ Error: {result['error']}\")\n",
    "        print(f\"   âœ“ Raw Response: {result['raw_response'].strip().replace('\\n', '')}\")\n",
    "    else:\n",
    "        print(f\"   âœ“ Response: {\", \".join(result[\"detected_pii\"][\"pii\"])}\")\n",
    "\n",
    "def print_sample_data(sample):\n",
    "    # Show sample text\n",
    "    print(f\"\\nðŸ“„ Text: {sample['source_text']}\")\n",
    "\n",
    "    # Show expected PII (ground truth)\n",
    "    print(f\"\\nðŸ·ï¸  Expected PII ({len(sample['privacy_mask'])} items):\")\n",
    "    for pii_item in sample['privacy_mask']:\n",
    "        print(f\"   â€¢ {pii_item['label']:20s} : '{pii_item['value']}'\")\n",
    "\n",
    "def print_header(sample):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing Sample {i} (ID: {sample['id']})\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "def test_prompt_with_models(samples, get_prompt: Callable[[str], str]):\n",
    "    results_for_prompt_per_model: dict[str, list[object]] = {}\n",
    "    for i, sample in enumerate(samples):\n",
    "        # Test with each model\n",
    "        for model_name in models_to_test:\n",
    "            result = detect_pii_with_model(sample, model_name, client, get_prompt)\n",
    "            results_for_prompt_per_model.setdefault(model_name, []).append(result)\n",
    "    return results_for_prompt_per_model\n",
    "\n",
    "def print_results_for_prompt(results_for_prompt_per_model: dict[str, list[object]], samples, num_samples_to_print):\n",
    "    for i in range(num_samples_to_print):\n",
    "        print_header(samples[i])\n",
    "        print_sample_data(samples[i])\n",
    "\n",
    "        for model_name in models_to_test:\n",
    "            print(f\"\\nðŸ¤– Testing with {model_name}...\")\n",
    "            print_result(results_for_prompt_per_model[model_name][i])"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Simple PII Detection Prompt\n",
    "\n",
    "Create a prompt that asks the LLM to identify all PII in the text."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:53:19.435564Z",
     "start_time": "2026-01-13T18:53:19.432174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gety_pii_prompt_simplest(text):\n",
    "    \"\"\"Create a prompt for PII detection.\"\"\"\n",
    "    return f\"\"\"For the text provided below identify all personally identifiable information (PII) in it.\n",
    "               Return your response as a JSON array that contains all the portions of text identified as PII.\n",
    "               Only return the JSON, no additional text. JSON array should be named pii, for example {{'pii': ['value1', 'value']}}.\n",
    "               Text to analyze: {text}\n",
    "               \"\"\"\n"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Call simple prompt"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:54:07.120642Z",
     "start_time": "2026-01-13T18:53:22.102705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# process all the samples\n",
    "results_for_prompt_per_model = test_prompt_with_models(samples, gety_pii_prompt_simplest)"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:54:07.136278Z",
     "start_time": "2026-01-13T18:54:07.131423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print first N results\n",
    "print_results_for_prompt(results_for_prompt_per_model, samples, 5)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing Sample 4 (ID: 175761)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Text: To settle the charges of Pakistan Rupee746,208.95 for your 9 Non-binary child's counseling sessions, kindly use the attached american_express 5943919109159496.\n",
      "\n",
      "ðŸ·ï¸  Expected PII (6 items):\n",
      "   â€¢ CURRENCY             : 'Pakistan Rupee'\n",
      "   â€¢ AMOUNT               : '746,208.95'\n",
      "   â€¢ AGE                  : '9'\n",
      "   â€¢ GENDER               : 'Non-binary'\n",
      "   â€¢ CREDITCARDISSUER     : 'american_express'\n",
      "   â€¢ CREDITCARDNUMBER     : '5943919109159496'\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: Pakistan Rupee746,208.95, 9 Non-binary child's counseling sessions, american_express 5943919109159496\n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: Pakistan Rupee746,208.95, 9 Non-binary child's counseling sessions, american_express 5943919109159496, 5943919109159496\n",
      "\n",
      "================================================================================\n",
      "Processing Sample 4 (ID: 175762)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Text: Bobby_Wisozk has noted violations of Port Muriel's zoning laws for commercial property on Toy Landing. A cease and desist order expected.\n",
      "\n",
      "ðŸ·ï¸  Expected PII (3 items):\n",
      "   â€¢ USERNAME             : 'Bobby_Wisozk'\n",
      "   â€¢ CITY                 : 'Port Muriel'\n",
      "   â€¢ STREET               : 'Toy Landing'\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: Bobby_Wisozk, Port Muriel, Toy Landing\n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: Bobby_Wisozk, Port Muriel, Toy Landing\n",
      "\n",
      "================================================================================\n",
      "Processing Sample 4 (ID: 175763)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Text: Your finance team has been tasked with creating a detailed report on all our assets and liabilities. Please send me the report on my secondary email at Apt. 508. Use the password yIh8ROIfIkPl for any encrypted files.\n",
      "\n",
      "ðŸ·ï¸  Expected PII (2 items):\n",
      "   â€¢ SECONDARYADDRESS     : 'Apt. 508'\n",
      "   â€¢ PASSWORD             : 'yIh8ROIfIkPl'\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: Apt. 508, yIh8ROIfIkPl\n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: Apt. 508, yIh8ROIfIkPl\n",
      "\n",
      "================================================================================\n",
      "Processing Sample 4 (ID: 175764)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Text: The Arts Education plan for this semester includes a talk from 1kLwc9VckFtgAJQ1aM3WneZAuyBu from [-71.3107,55.0959]\n",
      "\n",
      "ðŸ·ï¸  Expected PII (2 items):\n",
      "   â€¢ BITCOINADDRESS       : '1kLwc9VckFtgAJQ1aM3WneZAuyBu'\n",
      "   â€¢ NEARBYGPSCOORDINATE  : '[-71.3107,55.0959]'\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: \n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: 1kLwc9VckFtgAJQ1aM3WneZAuyBu, [-71.3107,55.0959]\n",
      "\n",
      "================================================================================\n",
      "Processing Sample 4 (ID: 175765)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Text: In light of recent developments, please advise about updating our patent strategy. You can reach out to our office at Apt. 926, Washington County. Regards, The Assistant.\n",
      "\n",
      "ðŸ·ï¸  Expected PII (3 items):\n",
      "   â€¢ SECONDARYADDRESS     : 'Apt. 926'\n",
      "   â€¢ COUNTY               : 'Washington County'\n",
      "   â€¢ JOBTYPE              : 'Assistant'\n",
      "\n",
      "ðŸ¤– Testing with gpt-4o-mini...\n",
      "   âœ“ Response: Apt. 926, Washington County\n",
      "\n",
      "ðŸ¤– Testing with gpt-5.2...\n",
      "   âœ“ Response: Apt. 926, Washington County\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate the stats"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:54:35.777706Z",
     "start_time": "2026-01-13T18:54:35.771284Z"
    }
   },
   "cell_type": "code",
   "source": "def calculate_stats_for_model(model_results):\n    \"\"\"\n    Calculate PII detection statistics for a single model.\n    \n    Args:\n        model_results: List of result objects from detect_pii_with_model\n        \n    Returns:\n        dict: Statistics including missed count, extra count, and details\n    \"\"\"\n    total_ground_truth = 0\n    total_detected = 0\n    total_missed = 0\n    total_extra = 0\n    sample_details = []\n    \n    for result in model_results:\n        if 'error' in result:\n            # Skip samples with errors\n            continue\n            \n        # Get ground truth values\n        ground_truth_values = set(item['value'] for item in result['ground_truth'])\n        \n        # Get detected values\n        detected_values = set(result.get('detected_pii', {}).get('pii', []))\n        \n        # Calculate missed (in ground truth but not detected)\n        missed = ground_truth_values - detected_values\n        \n        # Calculate extra (detected but not in ground truth)\n        extra = detected_values - ground_truth_values\n        \n        # Calculate correct (intersection)\n        correct = ground_truth_values & detected_values\n        \n        total_ground_truth += len(ground_truth_values)\n        total_detected += len(detected_values)\n        total_missed += len(missed)\n        total_extra += len(extra)\n        \n        sample_details.append({\n            'sample_id': result['sample_id'],\n            'ground_truth_count': len(ground_truth_values),\n            'detected_count': len(detected_values),\n            'correct_count': len(correct),\n            'missed_count': len(missed),\n            'extra_count': len(extra),\n            'missed_values': list(missed),\n            'extra_values': list(extra)\n        })\n    \n    # Calculate rates\n    recall = (total_ground_truth - total_missed) / total_ground_truth if total_ground_truth > 0 else 0\n    precision = (total_detected - total_extra) / total_detected if total_detected > 0 else 0\n    \n    return {\n        'total_ground_truth': total_ground_truth,\n        'total_detected': total_detected,\n        'total_missed': total_missed,\n        'total_extra': total_extra,\n        'recall': recall,\n        'precision': precision,\n        'sample_details': sample_details\n    }",
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_stats_for_all_models(results_per_model):\n",
    "    \"\"\"\n",
    "    Calculate PII detection statistics for all models.\n",
    "    \n",
    "    Args:\n",
    "        results_per_model: Dict mapping model name to list of result objects\n",
    "        \n",
    "    Returns:\n",
    "        dict: Statistics per model\n",
    "    \"\"\"\n",
    "    all_stats = {}\n",
    "    \n",
    "    for model_name, model_results in results_per_model.items():\n",
    "        stats = calculate_stats_for_model(model_results)\n",
    "        all_stats[model_name] = stats\n",
    "    \n",
    "    return all_stats\n",
    "\n",
    "\n",
    "def print_stats(all_stats):\n",
    "    \"\"\"Print statistics in a formatted way.\"\"\"\n",
    "    for model_name, stats in all_stats.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Statistics for {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total ground truth PII: {stats['total_ground_truth']}\")\n",
    "        print(f\"Total detected PII:     {stats['total_detected']}\")\n",
    "        print(f\"Total missed:           {stats['total_missed']}\")\n",
    "        print(f\"Total extra (false +):  {stats['total_extra']}\")\n",
    "        print(f\"Recall:                 {stats['recall']:.2%}\")\n",
    "        print(f\"  Recall measures how many of the actual PII items were successfully detected.\")\n",
    "        print(f\"  It answers: 'Of all the PII that exists in the text, what percentage did we find?'\")\n",
    "        print(f\"Precision:              {stats['precision']:.2%}\")\n",
    "        print(f\"  Precision measures how many of the detected items were actually correct.\")\n",
    "        print(f\"  It answers: 'Of all the items we flagged as PII, what percentage were actually PII?'\")\n",
    "        \n",
    "        # print(f\"\\nPer-sample breakdown:\")\n",
    "        # for detail in stats['sample_details']:\n",
    "        #     print(f\"  Sample {detail['sample_id']}:\")\n",
    "        #     print(f\"    Ground truth: {detail['ground_truth_count']}, Detected: {detail['detected_count']}\")\n",
    "        #     print(f\"    Correct: {detail['correct_count']}, Missed: {detail['missed_count']}, Extra: {detail['extra_count']}\")\n",
    "        #     if detail['missed_values']:\n",
    "        #         print(f\"    Missed values: {detail['missed_values']}\")\n",
    "        #     if detail['extra_values']:\n",
    "        #         print(f\"    Extra values: {detail['extra_values']}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:54:36.825863Z",
     "start_time": "2026-01-13T18:54:36.820086Z"
    }
   },
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "source": "# Calculate and print statistics for all models\nall_stats = calculate_stats_for_all_models(results_for_prompt_per_model)\nprint_stats(all_stats)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T18:54:37.674358Z",
     "start_time": "2026-01-13T18:54:37.668915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Statistics for gpt-4o-mini\n",
      "============================================================\n",
      "Total ground truth PII: 64\n",
      "Total detected PII:     48\n",
      "Total missed:           24\n",
      "Total extra (false +):  8\n",
      "Recall:                 62.50%\n",
      "  Recall measures how many of the actual PII items were successfully detected.\n",
      "  It answers: 'Of all the PII that exists in the text, what percentage did we find?'\n",
      "Precision:              83.33%\n",
      "  Precision measures how many of the detected items were actually correct.\n",
      "  It answers: 'Of all the items we flagged as PII, what percentage were actually PII?'\n",
      "\n",
      "============================================================\n",
      "Statistics for gpt-5.2\n",
      "============================================================\n",
      "Total ground truth PII: 64\n",
      "Total detected PII:     50\n",
      "Total missed:           23\n",
      "Total extra (false +):  9\n",
      "Recall:                 64.06%\n",
      "  Recall measures how many of the actual PII items were successfully detected.\n",
      "  It answers: 'Of all the PII that exists in the text, what percentage did we find?'\n",
      "Precision:              82.00%\n",
      "  Precision measures how many of the detected items were actually correct.\n",
      "  It answers: 'Of all the items we flagged as PII, what percentage were actually PII?'\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
